[package]
name = "tokenizers"
version = "0.12.0"
edition = "2018"
publish = false
repository = "https://github.com/hotg-ai/proc-blocks"
description = "A proc-block takes a passage and a question as input and gives us BERT Encoding in form of input_ids, input_masks, segment_ids as output"

# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html

[lib]
crate-type = ["cdylib", "rlib"]

[dependencies]
lazy_static = { version = "1.4.0", features = ["spin_no_std"] }
hotg-rune-proc-blocks = {path = "../support"}
anyhow = { version = "1.0", default-features = false }
unicode-normalization = {version = "0.1.19", default-features =false}
wit-bindgen-rust = { git = "https://github.com/bytecodealliance/wit-bindgen" }

[package.metadata.wapm]
namespace = "hotg-ai"
abi = "none"
