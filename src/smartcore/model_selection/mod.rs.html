<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="rustdoc"><meta name="description" content="Source of the Rust file `/home/runner/.cargo/git/checkouts/smartcore-21ea4dcbae50956e/31f8612/src/model_selection/mod.rs`."><meta name="keywords" content="rust, rustlang, rust-lang"><title>mod.rs - source</title><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../SourceSerif4-Regular.ttf.woff2"><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../FiraSans-Regular.woff2"><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../FiraSans-Medium.woff2"><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../SourceCodePro-Regular.ttf.woff2"><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../SourceSerif4-Bold.ttf.woff2"><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../SourceCodePro-Semibold.ttf.woff2"><link rel="stylesheet" type="text/css" href="../../../normalize.css"><link rel="stylesheet" type="text/css" href="../../../rustdoc.css" id="mainThemeStyle"><link rel="stylesheet" type="text/css" href="../../../ayu.css" disabled><link rel="stylesheet" type="text/css" href="../../../dark.css" disabled><link rel="stylesheet" type="text/css" href="../../../light.css" id="themeStyle"><script id="default-settings" ></script><script src="../../../storage.js"></script><script defer src="../../../source-script.js"></script><script defer src="../../../source-files.js"></script><script defer src="../../../main.js"></script><noscript><link rel="stylesheet" href="../../../noscript.css"></noscript><link rel="alternate icon" type="image/png" href="../../../favicon-16x16.png"><link rel="alternate icon" type="image/png" href="../../../favicon-32x32.png"><link rel="icon" type="image/svg+xml" href="../../../favicon.svg"></head><body class="rustdoc source"><!--[if lte IE 11]><div class="warning">This old browser is unsupported and will most likely display funky things.</div><![endif]--><nav class="mobile-topbar"><button class="sidebar-menu-toggle">&#9776;</button><a class="sidebar-logo" href="../../../smartcore/index.html"><div class="logo-container"><img class="rust-logo" src="../../../rust-logo.svg" alt="logo"></div>
        </a><h2 class="location"></h2>
    </nav>
    <nav class="sidebar"><a class="sidebar-logo" href="../../../smartcore/index.html"><div class="logo-container"><img class="rust-logo" src="../../../rust-logo.svg" alt="logo"></div>
        </a></nav><main><div class="width-limiter"><div class="sub-container"><a class="sub-logo-container" href="../../../smartcore/index.html"><img class="rust-logo" src="../../../rust-logo.svg" alt="logo"></a><nav class="sub"><form class="search-form"><div class="search-container"><span></span><input class="search-input" name="search" autocomplete="off" spellcheck="false" placeholder="Click or press ‘S’ to search, ‘?’ for more options…" type="search"><button type="button" id="help-button" title="help">?</button><div id="settings-menu" tabindex="-1">
                                <a href="../../../settings.html" title="settings"><img width="22" height="22" alt="Change settings" src="../../../wheel.svg"></a></div>
                        </div></form></nav></div><section id="main-content" class="content"><div class="example-wrap"><pre class="line-numbers"><span id="1">1</span>
<span id="2">2</span>
<span id="3">3</span>
<span id="4">4</span>
<span id="5">5</span>
<span id="6">6</span>
<span id="7">7</span>
<span id="8">8</span>
<span id="9">9</span>
<span id="10">10</span>
<span id="11">11</span>
<span id="12">12</span>
<span id="13">13</span>
<span id="14">14</span>
<span id="15">15</span>
<span id="16">16</span>
<span id="17">17</span>
<span id="18">18</span>
<span id="19">19</span>
<span id="20">20</span>
<span id="21">21</span>
<span id="22">22</span>
<span id="23">23</span>
<span id="24">24</span>
<span id="25">25</span>
<span id="26">26</span>
<span id="27">27</span>
<span id="28">28</span>
<span id="29">29</span>
<span id="30">30</span>
<span id="31">31</span>
<span id="32">32</span>
<span id="33">33</span>
<span id="34">34</span>
<span id="35">35</span>
<span id="36">36</span>
<span id="37">37</span>
<span id="38">38</span>
<span id="39">39</span>
<span id="40">40</span>
<span id="41">41</span>
<span id="42">42</span>
<span id="43">43</span>
<span id="44">44</span>
<span id="45">45</span>
<span id="46">46</span>
<span id="47">47</span>
<span id="48">48</span>
<span id="49">49</span>
<span id="50">50</span>
<span id="51">51</span>
<span id="52">52</span>
<span id="53">53</span>
<span id="54">54</span>
<span id="55">55</span>
<span id="56">56</span>
<span id="57">57</span>
<span id="58">58</span>
<span id="59">59</span>
<span id="60">60</span>
<span id="61">61</span>
<span id="62">62</span>
<span id="63">63</span>
<span id="64">64</span>
<span id="65">65</span>
<span id="66">66</span>
<span id="67">67</span>
<span id="68">68</span>
<span id="69">69</span>
<span id="70">70</span>
<span id="71">71</span>
<span id="72">72</span>
<span id="73">73</span>
<span id="74">74</span>
<span id="75">75</span>
<span id="76">76</span>
<span id="77">77</span>
<span id="78">78</span>
<span id="79">79</span>
<span id="80">80</span>
<span id="81">81</span>
<span id="82">82</span>
<span id="83">83</span>
<span id="84">84</span>
<span id="85">85</span>
<span id="86">86</span>
<span id="87">87</span>
<span id="88">88</span>
<span id="89">89</span>
<span id="90">90</span>
<span id="91">91</span>
<span id="92">92</span>
<span id="93">93</span>
<span id="94">94</span>
<span id="95">95</span>
<span id="96">96</span>
<span id="97">97</span>
<span id="98">98</span>
<span id="99">99</span>
<span id="100">100</span>
<span id="101">101</span>
<span id="102">102</span>
<span id="103">103</span>
<span id="104">104</span>
<span id="105">105</span>
<span id="106">106</span>
<span id="107">107</span>
<span id="108">108</span>
<span id="109">109</span>
<span id="110">110</span>
<span id="111">111</span>
<span id="112">112</span>
<span id="113">113</span>
<span id="114">114</span>
<span id="115">115</span>
<span id="116">116</span>
<span id="117">117</span>
<span id="118">118</span>
<span id="119">119</span>
<span id="120">120</span>
<span id="121">121</span>
<span id="122">122</span>
<span id="123">123</span>
<span id="124">124</span>
<span id="125">125</span>
<span id="126">126</span>
<span id="127">127</span>
<span id="128">128</span>
<span id="129">129</span>
<span id="130">130</span>
<span id="131">131</span>
<span id="132">132</span>
<span id="133">133</span>
<span id="134">134</span>
<span id="135">135</span>
<span id="136">136</span>
<span id="137">137</span>
<span id="138">138</span>
<span id="139">139</span>
<span id="140">140</span>
<span id="141">141</span>
<span id="142">142</span>
<span id="143">143</span>
<span id="144">144</span>
<span id="145">145</span>
<span id="146">146</span>
<span id="147">147</span>
<span id="148">148</span>
<span id="149">149</span>
<span id="150">150</span>
<span id="151">151</span>
<span id="152">152</span>
<span id="153">153</span>
<span id="154">154</span>
<span id="155">155</span>
<span id="156">156</span>
<span id="157">157</span>
<span id="158">158</span>
<span id="159">159</span>
<span id="160">160</span>
<span id="161">161</span>
<span id="162">162</span>
<span id="163">163</span>
<span id="164">164</span>
<span id="165">165</span>
<span id="166">166</span>
<span id="167">167</span>
<span id="168">168</span>
<span id="169">169</span>
<span id="170">170</span>
<span id="171">171</span>
<span id="172">172</span>
<span id="173">173</span>
<span id="174">174</span>
<span id="175">175</span>
<span id="176">176</span>
<span id="177">177</span>
<span id="178">178</span>
<span id="179">179</span>
<span id="180">180</span>
<span id="181">181</span>
<span id="182">182</span>
<span id="183">183</span>
<span id="184">184</span>
<span id="185">185</span>
<span id="186">186</span>
<span id="187">187</span>
<span id="188">188</span>
<span id="189">189</span>
<span id="190">190</span>
<span id="191">191</span>
<span id="192">192</span>
<span id="193">193</span>
<span id="194">194</span>
<span id="195">195</span>
<span id="196">196</span>
<span id="197">197</span>
<span id="198">198</span>
<span id="199">199</span>
<span id="200">200</span>
<span id="201">201</span>
<span id="202">202</span>
<span id="203">203</span>
<span id="204">204</span>
<span id="205">205</span>
<span id="206">206</span>
<span id="207">207</span>
<span id="208">208</span>
<span id="209">209</span>
<span id="210">210</span>
<span id="211">211</span>
<span id="212">212</span>
<span id="213">213</span>
<span id="214">214</span>
<span id="215">215</span>
<span id="216">216</span>
<span id="217">217</span>
<span id="218">218</span>
<span id="219">219</span>
<span id="220">220</span>
<span id="221">221</span>
<span id="222">222</span>
<span id="223">223</span>
<span id="224">224</span>
<span id="225">225</span>
<span id="226">226</span>
<span id="227">227</span>
<span id="228">228</span>
<span id="229">229</span>
<span id="230">230</span>
<span id="231">231</span>
<span id="232">232</span>
<span id="233">233</span>
<span id="234">234</span>
<span id="235">235</span>
<span id="236">236</span>
<span id="237">237</span>
<span id="238">238</span>
<span id="239">239</span>
<span id="240">240</span>
<span id="241">241</span>
<span id="242">242</span>
<span id="243">243</span>
<span id="244">244</span>
<span id="245">245</span>
<span id="246">246</span>
<span id="247">247</span>
<span id="248">248</span>
<span id="249">249</span>
<span id="250">250</span>
<span id="251">251</span>
<span id="252">252</span>
<span id="253">253</span>
<span id="254">254</span>
<span id="255">255</span>
<span id="256">256</span>
<span id="257">257</span>
<span id="258">258</span>
<span id="259">259</span>
<span id="260">260</span>
<span id="261">261</span>
<span id="262">262</span>
<span id="263">263</span>
<span id="264">264</span>
<span id="265">265</span>
<span id="266">266</span>
<span id="267">267</span>
<span id="268">268</span>
<span id="269">269</span>
<span id="270">270</span>
<span id="271">271</span>
<span id="272">272</span>
<span id="273">273</span>
<span id="274">274</span>
<span id="275">275</span>
<span id="276">276</span>
<span id="277">277</span>
<span id="278">278</span>
<span id="279">279</span>
<span id="280">280</span>
<span id="281">281</span>
<span id="282">282</span>
<span id="283">283</span>
<span id="284">284</span>
<span id="285">285</span>
<span id="286">286</span>
<span id="287">287</span>
<span id="288">288</span>
<span id="289">289</span>
<span id="290">290</span>
<span id="291">291</span>
<span id="292">292</span>
<span id="293">293</span>
<span id="294">294</span>
<span id="295">295</span>
<span id="296">296</span>
<span id="297">297</span>
<span id="298">298</span>
<span id="299">299</span>
<span id="300">300</span>
<span id="301">301</span>
<span id="302">302</span>
<span id="303">303</span>
<span id="304">304</span>
<span id="305">305</span>
<span id="306">306</span>
<span id="307">307</span>
<span id="308">308</span>
<span id="309">309</span>
<span id="310">310</span>
<span id="311">311</span>
<span id="312">312</span>
<span id="313">313</span>
<span id="314">314</span>
<span id="315">315</span>
<span id="316">316</span>
<span id="317">317</span>
<span id="318">318</span>
<span id="319">319</span>
<span id="320">320</span>
<span id="321">321</span>
<span id="322">322</span>
<span id="323">323</span>
<span id="324">324</span>
<span id="325">325</span>
<span id="326">326</span>
<span id="327">327</span>
<span id="328">328</span>
<span id="329">329</span>
<span id="330">330</span>
<span id="331">331</span>
<span id="332">332</span>
<span id="333">333</span>
<span id="334">334</span>
<span id="335">335</span>
<span id="336">336</span>
<span id="337">337</span>
<span id="338">338</span>
<span id="339">339</span>
<span id="340">340</span>
<span id="341">341</span>
<span id="342">342</span>
<span id="343">343</span>
<span id="344">344</span>
<span id="345">345</span>
<span id="346">346</span>
<span id="347">347</span>
<span id="348">348</span>
<span id="349">349</span>
<span id="350">350</span>
<span id="351">351</span>
<span id="352">352</span>
<span id="353">353</span>
<span id="354">354</span>
<span id="355">355</span>
<span id="356">356</span>
<span id="357">357</span>
<span id="358">358</span>
<span id="359">359</span>
<span id="360">360</span>
<span id="361">361</span>
<span id="362">362</span>
<span id="363">363</span>
<span id="364">364</span>
<span id="365">365</span>
<span id="366">366</span>
<span id="367">367</span>
<span id="368">368</span>
<span id="369">369</span>
<span id="370">370</span>
<span id="371">371</span>
<span id="372">372</span>
<span id="373">373</span>
<span id="374">374</span>
<span id="375">375</span>
<span id="376">376</span>
<span id="377">377</span>
<span id="378">378</span>
<span id="379">379</span>
<span id="380">380</span>
<span id="381">381</span>
<span id="382">382</span>
<span id="383">383</span>
<span id="384">384</span>
<span id="385">385</span>
<span id="386">386</span>
<span id="387">387</span>
<span id="388">388</span>
<span id="389">389</span>
<span id="390">390</span>
<span id="391">391</span>
<span id="392">392</span>
<span id="393">393</span>
<span id="394">394</span>
<span id="395">395</span>
<span id="396">396</span>
<span id="397">397</span>
<span id="398">398</span>
<span id="399">399</span>
<span id="400">400</span>
<span id="401">401</span>
<span id="402">402</span>
<span id="403">403</span>
<span id="404">404</span>
<span id="405">405</span>
<span id="406">406</span>
<span id="407">407</span>
<span id="408">408</span>
<span id="409">409</span>
<span id="410">410</span>
<span id="411">411</span>
<span id="412">412</span>
<span id="413">413</span>
<span id="414">414</span>
<span id="415">415</span>
<span id="416">416</span>
<span id="417">417</span>
<span id="418">418</span>
<span id="419">419</span>
<span id="420">420</span>
<span id="421">421</span>
<span id="422">422</span>
<span id="423">423</span>
<span id="424">424</span>
<span id="425">425</span>
<span id="426">426</span>
<span id="427">427</span>
<span id="428">428</span>
<span id="429">429</span>
<span id="430">430</span>
<span id="431">431</span>
<span id="432">432</span>
<span id="433">433</span>
<span id="434">434</span>
<span id="435">435</span>
<span id="436">436</span>
<span id="437">437</span>
<span id="438">438</span>
<span id="439">439</span>
<span id="440">440</span>
<span id="441">441</span>
<span id="442">442</span>
<span id="443">443</span>
<span id="444">444</span>
<span id="445">445</span>
<span id="446">446</span>
<span id="447">447</span>
<span id="448">448</span>
<span id="449">449</span>
<span id="450">450</span>
<span id="451">451</span>
<span id="452">452</span>
</pre><pre class="rust"><code><span class="doccomment">//! # Model Selection methods</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! In statistics and machine learning we usually split our data into two sets: one for training and the other one for testing.</span>
<span class="doccomment">//! We fit our model to the training data, in order to make predictions on the test data. We do that to avoid overfitting or underfitting model to our data.</span>
<span class="doccomment">//! Overfitting is bad because the model we trained fits trained data too well and can’t make any inferences on new data.</span>
<span class="doccomment">//! Underfitted is bad because the model is undetrained and does not fit the training data well.</span>
<span class="doccomment">//! Splitting data into multiple subsets helps us to find the right combination of hyperparameters, estimate model performance and choose the right model for</span>
<span class="doccomment">//! the data.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! In SmartCore a random split into training and test sets can be quickly computed with the [train_test_split](./fn.train_test_split.html) helper function.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//! use crate::smartcore::linalg::BaseMatrix;</span>
<span class="doccomment">//! use smartcore::linalg::naive::dense_matrix::DenseMatrix;</span>
<span class="doccomment">//! use smartcore::model_selection::train_test_split;</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! //Iris data</span>
<span class="doccomment">//! let x = DenseMatrix::from_2d_array(&amp;[</span>
<span class="doccomment">//!           &amp;[5.1, 3.5, 1.4, 0.2],</span>
<span class="doccomment">//!           &amp;[4.9, 3.0, 1.4, 0.2],</span>
<span class="doccomment">//!           &amp;[4.7, 3.2, 1.3, 0.2],</span>
<span class="doccomment">//!           &amp;[4.6, 3.1, 1.5, 0.2],</span>
<span class="doccomment">//!           &amp;[5.0, 3.6, 1.4, 0.2],</span>
<span class="doccomment">//!           &amp;[5.4, 3.9, 1.7, 0.4],</span>
<span class="doccomment">//!           &amp;[4.6, 3.4, 1.4, 0.3],</span>
<span class="doccomment">//!           &amp;[5.0, 3.4, 1.5, 0.2],</span>
<span class="doccomment">//!           &amp;[4.4, 2.9, 1.4, 0.2],</span>
<span class="doccomment">//!           &amp;[4.9, 3.1, 1.5, 0.1],</span>
<span class="doccomment">//!           &amp;[7.0, 3.2, 4.7, 1.4],</span>
<span class="doccomment">//!           &amp;[6.4, 3.2, 4.5, 1.5],</span>
<span class="doccomment">//!           &amp;[6.9, 3.1, 4.9, 1.5],</span>
<span class="doccomment">//!           &amp;[5.5, 2.3, 4.0, 1.3],</span>
<span class="doccomment">//!           &amp;[6.5, 2.8, 4.6, 1.5],</span>
<span class="doccomment">//!           &amp;[5.7, 2.8, 4.5, 1.3],</span>
<span class="doccomment">//!           &amp;[6.3, 3.3, 4.7, 1.6],</span>
<span class="doccomment">//!           &amp;[4.9, 2.4, 3.3, 1.0],</span>
<span class="doccomment">//!           &amp;[6.6, 2.9, 4.6, 1.3],</span>
<span class="doccomment">//!           &amp;[5.2, 2.7, 3.9, 1.4],</span>
<span class="doccomment">//!           ]);</span>
<span class="doccomment">//! let y: Vec&lt;f64&gt; = vec![</span>
<span class="doccomment">//!           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,</span>
<span class="doccomment">//! ];</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! let (x_train, x_test, y_train, y_test) = train_test_split(&amp;x, &amp;y, 0.2, true);</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! println!(&quot;X train: {:?}, y train: {}, X test: {:?}, y test: {}&quot;,</span>
<span class="doccomment">//!             x_train.shape(), y_train.len(), x_test.shape(), y_test.len());</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! When we partition the available data into two disjoint sets, we drastically reduce the number of samples that can be used for training.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! One way to solve this problem is to use k-fold cross-validation. With k-fold validation, the dataset is split into k disjoint sets.</span>
<span class="doccomment">//! A model is trained using k - 1 of the folds, and the resulting model is validated on the remaining portion of the data.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! The simplest way to run cross-validation is to use the [cross_val_score](./fn.cross_validate.html) helper function on your estimator and the dataset.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//! use smartcore::linalg::naive::dense_matrix::DenseMatrix;</span>
<span class="doccomment">//! use smartcore::model_selection::{KFold, cross_validate};</span>
<span class="doccomment">//! use smartcore::metrics::accuracy;</span>
<span class="doccomment">//! use smartcore::linear::logistic_regression::LogisticRegression;</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! //Iris data</span>
<span class="doccomment">//! let x = DenseMatrix::from_2d_array(&amp;[</span>
<span class="doccomment">//!           &amp;[5.1, 3.5, 1.4, 0.2],</span>
<span class="doccomment">//!           &amp;[4.9, 3.0, 1.4, 0.2],</span>
<span class="doccomment">//!           &amp;[4.7, 3.2, 1.3, 0.2],</span>
<span class="doccomment">//!           &amp;[4.6, 3.1, 1.5, 0.2],</span>
<span class="doccomment">//!           &amp;[5.0, 3.6, 1.4, 0.2],</span>
<span class="doccomment">//!           &amp;[5.4, 3.9, 1.7, 0.4],</span>
<span class="doccomment">//!           &amp;[4.6, 3.4, 1.4, 0.3],</span>
<span class="doccomment">//!           &amp;[5.0, 3.4, 1.5, 0.2],</span>
<span class="doccomment">//!           &amp;[4.4, 2.9, 1.4, 0.2],</span>
<span class="doccomment">//!           &amp;[4.9, 3.1, 1.5, 0.1],</span>
<span class="doccomment">//!           &amp;[7.0, 3.2, 4.7, 1.4],</span>
<span class="doccomment">//!           &amp;[6.4, 3.2, 4.5, 1.5],</span>
<span class="doccomment">//!           &amp;[6.9, 3.1, 4.9, 1.5],</span>
<span class="doccomment">//!           &amp;[5.5, 2.3, 4.0, 1.3],</span>
<span class="doccomment">//!           &amp;[6.5, 2.8, 4.6, 1.5],</span>
<span class="doccomment">//!           &amp;[5.7, 2.8, 4.5, 1.3],</span>
<span class="doccomment">//!           &amp;[6.3, 3.3, 4.7, 1.6],</span>
<span class="doccomment">//!           &amp;[4.9, 2.4, 3.3, 1.0],</span>
<span class="doccomment">//!           &amp;[6.6, 2.9, 4.6, 1.3],</span>
<span class="doccomment">//!           &amp;[5.2, 2.7, 3.9, 1.4],</span>
<span class="doccomment">//!           ]);</span>
<span class="doccomment">//! let y: Vec&lt;f64&gt; = vec![</span>
<span class="doccomment">//!           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,</span>
<span class="doccomment">//! ];</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! let cv = KFold::default().with_n_splits(3);</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! let results = cross_validate(LogisticRegression::fit,   //estimator</span>
<span class="doccomment">//!                                 &amp;x, &amp;y,                 //data</span>
<span class="doccomment">//!                                 Default::default(),     //hyperparameters</span>
<span class="doccomment">//!                                 cv,                     //cross validation split</span>
<span class="doccomment">//!                                 &amp;accuracy).unwrap();    //metric</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! println!(&quot;Training accuracy: {}, test accuracy: {}&quot;,</span>
<span class="doccomment">//!     results.mean_test_score(), results.mean_train_score());</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! The function [cross_val_predict](./fn.cross_val_predict.html) has a similar interface to `cross_val_score`,</span>
<span class="doccomment">//! but instead of test error it calculates predictions for all samples in the test set.</span>

<span class="kw">use</span> <span class="ident"><span class="kw">crate</span>::api::Predictor</span>;
<span class="kw">use</span> <span class="ident"><span class="kw">crate</span>::error::Failed</span>;
<span class="kw">use</span> <span class="ident"><span class="kw">crate</span>::linalg::BaseVector</span>;
<span class="kw">use</span> <span class="ident"><span class="kw">crate</span>::linalg::Matrix</span>;
<span class="kw">use</span> <span class="ident"><span class="kw">crate</span>::math::num::RealNumber</span>;
<span class="kw">use</span> <span class="ident">rand::seq::SliceRandom</span>;
<span class="kw">use</span> <span class="ident">rand::thread_rng</span>;

<span class="kw">pub</span>(<span class="kw">crate</span>) <span class="kw">mod</span> <span class="ident">kfold</span>;

<span class="kw">pub</span> <span class="kw">use</span> <span class="ident">kfold</span>::{<span class="ident">KFold</span>, <span class="ident">KFoldIter</span>};

<span class="doccomment">/// An interface for the K-Folds cross-validator</span>
<span class="kw">pub</span> <span class="kw">trait</span> <span class="ident">BaseKFold</span> {
    <span class="doccomment">/// An iterator over indices that split data into training and test set.</span>
    <span class="kw">type</span> <span class="ident">Output</span>: <span class="ident">Iterator</span><span class="op">&lt;</span><span class="ident">Item</span> <span class="op">=</span> (<span class="ident">Vec</span><span class="op">&lt;</span><span class="ident">usize</span><span class="op">&gt;</span>, <span class="ident">Vec</span><span class="op">&lt;</span><span class="ident">usize</span><span class="op">&gt;</span>)<span class="op">&gt;</span>;
    <span class="doccomment">/// Return a tuple containing the the training set indices for that split and</span>
    <span class="doccomment">/// the testing set indices for that split.</span>
    <span class="kw">fn</span> <span class="ident">split</span><span class="op">&lt;</span><span class="ident">T</span>: <span class="ident">RealNumber</span>, <span class="ident">M</span>: <span class="ident">Matrix</span><span class="op">&lt;</span><span class="ident">T</span><span class="op">&gt;</span><span class="op">&gt;</span>(<span class="kw-2">&amp;</span><span class="self">self</span>, <span class="ident">x</span>: <span class="kw-2">&amp;</span><span class="ident">M</span>) -&gt; <span class="ident"><span class="self">Self</span>::Output</span>;
    <span class="doccomment">/// Returns the number of splits</span>
    <span class="kw">fn</span> <span class="ident">n_splits</span>(<span class="kw-2">&amp;</span><span class="self">self</span>) -&gt; <span class="ident">usize</span>;
}

<span class="doccomment">/// Splits data into 2 disjoint datasets.</span>
<span class="doccomment">/// * `x` - features, matrix of size _NxM_ where _N_ is number of samples and _M_ is number of attributes.</span>
<span class="doccomment">/// * `y` - target values, should be of size _N_</span>
<span class="doccomment">/// * `test_size`, (0, 1] - the proportion of the dataset to include in the test split.</span>
<span class="doccomment">/// * `shuffle`, - whether or not to shuffle the data before splitting</span>
<span class="kw">pub</span> <span class="kw">fn</span> <span class="ident">train_test_split</span><span class="op">&lt;</span><span class="ident">T</span>: <span class="ident">RealNumber</span>, <span class="ident">M</span>: <span class="ident">Matrix</span><span class="op">&lt;</span><span class="ident">T</span><span class="op">&gt;</span><span class="op">&gt;</span>(
    <span class="ident">x</span>: <span class="kw-2">&amp;</span><span class="ident">M</span>,
    <span class="ident">y</span>: <span class="kw-2">&amp;</span><span class="ident">M::RowVector</span>,
    <span class="ident">test_size</span>: <span class="ident">f32</span>,
    <span class="ident">shuffle</span>: <span class="ident">bool</span>,
) -&gt; (<span class="ident">M</span>, <span class="ident">M</span>, <span class="ident">M::RowVector</span>, <span class="ident">M::RowVector</span>) {
    <span class="kw">if</span> <span class="ident">x</span>.<span class="ident">shape</span>().<span class="number">0</span> <span class="op">!</span><span class="op">=</span> <span class="ident">y</span>.<span class="ident">len</span>() {
        <span class="macro">panic!</span>(
            <span class="string">&quot;x and y should have the same number of samples. |x|: {}, |y|: {}&quot;</span>,
            <span class="ident">x</span>.<span class="ident">shape</span>().<span class="number">0</span>,
            <span class="ident">y</span>.<span class="ident">len</span>()
        );
    }

    <span class="kw">if</span> <span class="ident">test_size</span> <span class="op">&lt;</span><span class="op">=</span> <span class="number">0.</span> <span class="op">|</span><span class="op">|</span> <span class="ident">test_size</span> <span class="op">&gt;</span> <span class="number">1.0</span> {
        <span class="macro">panic!</span>(<span class="string">&quot;test_size should be between 0 and 1&quot;</span>);
    }

    <span class="kw">let</span> <span class="ident">n</span> <span class="op">=</span> <span class="ident">y</span>.<span class="ident">len</span>();

    <span class="kw">let</span> <span class="ident">n_test</span> <span class="op">=</span> ((<span class="ident">n</span> <span class="kw">as</span> <span class="ident">f32</span>) <span class="op">*</span> <span class="ident">test_size</span>) <span class="kw">as</span> <span class="ident">usize</span>;

    <span class="kw">if</span> <span class="ident">n_test</span> <span class="op">&lt;</span> <span class="number">1</span> {
        <span class="macro">panic!</span>(<span class="string">&quot;number of sample is too small {}&quot;</span>, <span class="ident">n</span>);
    }

    <span class="kw">let</span> <span class="kw-2">mut</span> <span class="ident">indices</span>: <span class="ident">Vec</span><span class="op">&lt;</span><span class="ident">usize</span><span class="op">&gt;</span> <span class="op">=</span> (<span class="number">0</span>..<span class="ident">n</span>).<span class="ident">collect</span>();

    <span class="kw">if</span> <span class="ident">shuffle</span> {
        <span class="ident">indices</span>.<span class="ident">shuffle</span>(<span class="kw-2">&amp;mut</span> <span class="ident">thread_rng</span>());
    }

    <span class="kw">let</span> <span class="ident">x_train</span> <span class="op">=</span> <span class="ident">x</span>.<span class="ident">take</span>(<span class="kw-2">&amp;</span><span class="ident">indices</span>[<span class="ident">n_test</span>..<span class="ident">n</span>], <span class="number">0</span>);
    <span class="kw">let</span> <span class="ident">x_test</span> <span class="op">=</span> <span class="ident">x</span>.<span class="ident">take</span>(<span class="kw-2">&amp;</span><span class="ident">indices</span>[<span class="number">0</span>..<span class="ident">n_test</span>], <span class="number">0</span>);
    <span class="kw">let</span> <span class="ident">y_train</span> <span class="op">=</span> <span class="ident">y</span>.<span class="ident">take</span>(<span class="kw-2">&amp;</span><span class="ident">indices</span>[<span class="ident">n_test</span>..<span class="ident">n</span>]);
    <span class="kw">let</span> <span class="ident">y_test</span> <span class="op">=</span> <span class="ident">y</span>.<span class="ident">take</span>(<span class="kw-2">&amp;</span><span class="ident">indices</span>[<span class="number">0</span>..<span class="ident">n_test</span>]);

    (<span class="ident">x_train</span>, <span class="ident">x_test</span>, <span class="ident">y_train</span>, <span class="ident">y_test</span>)
}

<span class="doccomment">/// Cross validation results.</span>
<span class="attribute">#[<span class="ident">derive</span>(<span class="ident">Clone</span>, <span class="ident">Debug</span>)]</span>
<span class="kw">pub</span> <span class="kw">struct</span> <span class="ident">CrossValidationResult</span><span class="op">&lt;</span><span class="ident">T</span>: <span class="ident">RealNumber</span><span class="op">&gt;</span> {
    <span class="doccomment">/// Vector with test scores on each cv split</span>
    <span class="kw">pub</span> <span class="ident">test_score</span>: <span class="ident">Vec</span><span class="op">&lt;</span><span class="ident">T</span><span class="op">&gt;</span>,
    <span class="doccomment">/// Vector with training scores on each cv split</span>
    <span class="kw">pub</span> <span class="ident">train_score</span>: <span class="ident">Vec</span><span class="op">&lt;</span><span class="ident">T</span><span class="op">&gt;</span>,
}

<span class="kw">impl</span><span class="op">&lt;</span><span class="ident">T</span>: <span class="ident">RealNumber</span><span class="op">&gt;</span> <span class="ident">CrossValidationResult</span><span class="op">&lt;</span><span class="ident">T</span><span class="op">&gt;</span> {
    <span class="doccomment">/// Average test score</span>
    <span class="kw">pub</span> <span class="kw">fn</span> <span class="ident">mean_test_score</span>(<span class="kw-2">&amp;</span><span class="self">self</span>) -&gt; <span class="ident">T</span> {
        <span class="self">self</span>.<span class="ident">test_score</span>.<span class="ident">sum</span>() <span class="op">/</span> <span class="ident">T::from_usize</span>(<span class="self">self</span>.<span class="ident">test_score</span>.<span class="ident">len</span>()).<span class="ident">unwrap</span>()
    }
    <span class="doccomment">/// Average training score</span>
    <span class="kw">pub</span> <span class="kw">fn</span> <span class="ident">mean_train_score</span>(<span class="kw-2">&amp;</span><span class="self">self</span>) -&gt; <span class="ident">T</span> {
        <span class="self">self</span>.<span class="ident">train_score</span>.<span class="ident">sum</span>() <span class="op">/</span> <span class="ident">T::from_usize</span>(<span class="self">self</span>.<span class="ident">train_score</span>.<span class="ident">len</span>()).<span class="ident">unwrap</span>()
    }
}

<span class="doccomment">/// Evaluate an estimator by cross-validation using given metric.</span>
<span class="doccomment">/// * `fit_estimator` - a `fit` function of an estimator</span>
<span class="doccomment">/// * `x` - features, matrix of size _NxM_ where _N_ is number of samples and _M_ is number of attributes.</span>
<span class="doccomment">/// * `y` - target values, should be of size _N_</span>
<span class="doccomment">/// * `parameters` - parameters of selected estimator. Use `Default::default()` for default parameters.</span>
<span class="doccomment">/// * `cv` - the cross-validation splitting strategy, should be an instance of [`BaseKFold`](./trait.BaseKFold.html)</span>
<span class="doccomment">/// * `score` - a metric to use for evaluation, see [metrics](../metrics/index.html)</span>
<span class="kw">pub</span> <span class="kw">fn</span> <span class="ident">cross_validate</span><span class="op">&lt;</span><span class="ident">T</span>, <span class="ident">M</span>, <span class="ident">H</span>, <span class="ident">E</span>, <span class="ident">K</span>, <span class="ident">F</span>, <span class="ident">S</span><span class="op">&gt;</span>(
    <span class="ident">fit_estimator</span>: <span class="ident">F</span>,
    <span class="ident">x</span>: <span class="kw-2">&amp;</span><span class="ident">M</span>,
    <span class="ident">y</span>: <span class="kw-2">&amp;</span><span class="ident">M::RowVector</span>,
    <span class="ident">parameters</span>: <span class="ident">H</span>,
    <span class="ident">cv</span>: <span class="ident">K</span>,
    <span class="ident">score</span>: <span class="ident">S</span>,
) -&gt; <span class="prelude-ty">Result</span><span class="op">&lt;</span><span class="ident">CrossValidationResult</span><span class="op">&lt;</span><span class="ident">T</span><span class="op">&gt;</span>, <span class="ident">Failed</span><span class="op">&gt;</span>
<span class="kw">where</span>
    <span class="ident">T</span>: <span class="ident">RealNumber</span>,
    <span class="ident">M</span>: <span class="ident">Matrix</span><span class="op">&lt;</span><span class="ident">T</span><span class="op">&gt;</span>,
    <span class="ident">H</span>: <span class="ident">Clone</span>,
    <span class="ident">E</span>: <span class="ident">Predictor</span><span class="op">&lt;</span><span class="ident">M</span>, <span class="ident">M::RowVector</span><span class="op">&gt;</span>,
    <span class="ident">K</span>: <span class="ident">BaseKFold</span>,
    <span class="ident">F</span>: <span class="ident">Fn</span>(<span class="kw-2">&amp;</span><span class="ident">M</span>, <span class="kw-2">&amp;</span><span class="ident">M::RowVector</span>, <span class="ident">H</span>) -&gt; <span class="prelude-ty">Result</span><span class="op">&lt;</span><span class="ident">E</span>, <span class="ident">Failed</span><span class="op">&gt;</span>,
    <span class="ident">S</span>: <span class="ident">Fn</span>(<span class="kw-2">&amp;</span><span class="ident">M::RowVector</span>, <span class="kw-2">&amp;</span><span class="ident">M::RowVector</span>) -&gt; <span class="ident">T</span>,
{
    <span class="kw">let</span> <span class="ident">k</span> <span class="op">=</span> <span class="ident">cv</span>.<span class="ident">n_splits</span>();
    <span class="kw">let</span> <span class="kw-2">mut</span> <span class="ident">test_score</span> <span class="op">=</span> <span class="ident">Vec::with_capacity</span>(<span class="ident">k</span>);
    <span class="kw">let</span> <span class="kw-2">mut</span> <span class="ident">train_score</span> <span class="op">=</span> <span class="ident">Vec::with_capacity</span>(<span class="ident">k</span>);

    <span class="kw">for</span> (<span class="ident">train_idx</span>, <span class="ident">test_idx</span>) <span class="kw">in</span> <span class="ident">cv</span>.<span class="ident">split</span>(<span class="ident">x</span>) {
        <span class="kw">let</span> <span class="ident">train_x</span> <span class="op">=</span> <span class="ident">x</span>.<span class="ident">take</span>(<span class="kw-2">&amp;</span><span class="ident">train_idx</span>, <span class="number">0</span>);
        <span class="kw">let</span> <span class="ident">train_y</span> <span class="op">=</span> <span class="ident">y</span>.<span class="ident">take</span>(<span class="kw-2">&amp;</span><span class="ident">train_idx</span>);
        <span class="kw">let</span> <span class="ident">test_x</span> <span class="op">=</span> <span class="ident">x</span>.<span class="ident">take</span>(<span class="kw-2">&amp;</span><span class="ident">test_idx</span>, <span class="number">0</span>);
        <span class="kw">let</span> <span class="ident">test_y</span> <span class="op">=</span> <span class="ident">y</span>.<span class="ident">take</span>(<span class="kw-2">&amp;</span><span class="ident">test_idx</span>);

        <span class="kw">let</span> <span class="ident">estimator</span> <span class="op">=</span> <span class="ident">fit_estimator</span>(<span class="kw-2">&amp;</span><span class="ident">train_x</span>, <span class="kw-2">&amp;</span><span class="ident">train_y</span>, <span class="ident">parameters</span>.<span class="ident">clone</span>())<span class="question-mark">?</span>;

        <span class="ident">train_score</span>.<span class="ident">push</span>(<span class="ident">score</span>(<span class="kw-2">&amp;</span><span class="ident">train_y</span>, <span class="kw-2">&amp;</span><span class="ident">estimator</span>.<span class="ident">predict</span>(<span class="kw-2">&amp;</span><span class="ident">train_x</span>)<span class="question-mark">?</span>));
        <span class="ident">test_score</span>.<span class="ident">push</span>(<span class="ident">score</span>(<span class="kw-2">&amp;</span><span class="ident">test_y</span>, <span class="kw-2">&amp;</span><span class="ident">estimator</span>.<span class="ident">predict</span>(<span class="kw-2">&amp;</span><span class="ident">test_x</span>)<span class="question-mark">?</span>));
    }

    <span class="prelude-val">Ok</span>(<span class="ident">CrossValidationResult</span> {
        <span class="ident">test_score</span>,
        <span class="ident">train_score</span>,
    })
}

<span class="doccomment">/// Generate cross-validated estimates for each input data point.</span>
<span class="doccomment">/// The data is split according to the cv parameter. Each sample belongs to exactly one test set, and its prediction is computed with an estimator fitted on the corresponding training set.</span>
<span class="doccomment">/// * `fit_estimator` - a `fit` function of an estimator</span>
<span class="doccomment">/// * `x` - features, matrix of size _NxM_ where _N_ is number of samples and _M_ is number of attributes.</span>
<span class="doccomment">/// * `y` - target values, should be of size _N_</span>
<span class="doccomment">/// * `parameters` - parameters of selected estimator. Use `Default::default()` for default parameters.</span>
<span class="doccomment">/// * `cv` - the cross-validation splitting strategy, should be an instance of [`BaseKFold`](./trait.BaseKFold.html)</span>
<span class="kw">pub</span> <span class="kw">fn</span> <span class="ident">cross_val_predict</span><span class="op">&lt;</span><span class="ident">T</span>, <span class="ident">M</span>, <span class="ident">H</span>, <span class="ident">E</span>, <span class="ident">K</span>, <span class="ident">F</span><span class="op">&gt;</span>(
    <span class="ident">fit_estimator</span>: <span class="ident">F</span>,
    <span class="ident">x</span>: <span class="kw-2">&amp;</span><span class="ident">M</span>,
    <span class="ident">y</span>: <span class="kw-2">&amp;</span><span class="ident">M::RowVector</span>,
    <span class="ident">parameters</span>: <span class="ident">H</span>,
    <span class="ident">cv</span>: <span class="ident">K</span>,
) -&gt; <span class="prelude-ty">Result</span><span class="op">&lt;</span><span class="ident">M::RowVector</span>, <span class="ident">Failed</span><span class="op">&gt;</span>
<span class="kw">where</span>
    <span class="ident">T</span>: <span class="ident">RealNumber</span>,
    <span class="ident">M</span>: <span class="ident">Matrix</span><span class="op">&lt;</span><span class="ident">T</span><span class="op">&gt;</span>,
    <span class="ident">H</span>: <span class="ident">Clone</span>,
    <span class="ident">E</span>: <span class="ident">Predictor</span><span class="op">&lt;</span><span class="ident">M</span>, <span class="ident">M::RowVector</span><span class="op">&gt;</span>,
    <span class="ident">K</span>: <span class="ident">BaseKFold</span>,
    <span class="ident">F</span>: <span class="ident">Fn</span>(<span class="kw-2">&amp;</span><span class="ident">M</span>, <span class="kw-2">&amp;</span><span class="ident">M::RowVector</span>, <span class="ident">H</span>) -&gt; <span class="prelude-ty">Result</span><span class="op">&lt;</span><span class="ident">E</span>, <span class="ident">Failed</span><span class="op">&gt;</span>,
{
    <span class="kw">let</span> <span class="kw-2">mut</span> <span class="ident">y_hat</span> <span class="op">=</span> <span class="ident">M::RowVector::zeros</span>(<span class="ident">y</span>.<span class="ident">len</span>());

    <span class="kw">for</span> (<span class="ident">train_idx</span>, <span class="ident">test_idx</span>) <span class="kw">in</span> <span class="ident">cv</span>.<span class="ident">split</span>(<span class="ident">x</span>) {
        <span class="kw">let</span> <span class="ident">train_x</span> <span class="op">=</span> <span class="ident">x</span>.<span class="ident">take</span>(<span class="kw-2">&amp;</span><span class="ident">train_idx</span>, <span class="number">0</span>);
        <span class="kw">let</span> <span class="ident">train_y</span> <span class="op">=</span> <span class="ident">y</span>.<span class="ident">take</span>(<span class="kw-2">&amp;</span><span class="ident">train_idx</span>);
        <span class="kw">let</span> <span class="ident">test_x</span> <span class="op">=</span> <span class="ident">x</span>.<span class="ident">take</span>(<span class="kw-2">&amp;</span><span class="ident">test_idx</span>, <span class="number">0</span>);

        <span class="kw">let</span> <span class="ident">estimator</span> <span class="op">=</span> <span class="ident">fit_estimator</span>(<span class="kw-2">&amp;</span><span class="ident">train_x</span>, <span class="kw-2">&amp;</span><span class="ident">train_y</span>, <span class="ident">parameters</span>.<span class="ident">clone</span>())<span class="question-mark">?</span>;

        <span class="kw">let</span> <span class="ident">y_test_hat</span> <span class="op">=</span> <span class="ident">estimator</span>.<span class="ident">predict</span>(<span class="kw-2">&amp;</span><span class="ident">test_x</span>)<span class="question-mark">?</span>;
        <span class="kw">for</span> (<span class="ident">i</span>, <span class="kw-2">&amp;</span><span class="ident">idx</span>) <span class="kw">in</span> <span class="ident">test_idx</span>.<span class="ident">iter</span>().<span class="ident">enumerate</span>() {
            <span class="ident">y_hat</span>.<span class="ident">set</span>(<span class="ident">idx</span>, <span class="ident">y_test_hat</span>.<span class="ident">get</span>(<span class="ident">i</span>));
        }
    }

    <span class="prelude-val">Ok</span>(<span class="ident">y_hat</span>)
}

<span class="attribute">#[<span class="ident">cfg</span>(<span class="ident">test</span>)]</span>
<span class="kw">mod</span> <span class="ident">tests</span> {

    <span class="kw">use</span> <span class="kw">super</span>::<span class="kw-2">*</span>;
    <span class="kw">use</span> <span class="ident"><span class="kw">crate</span>::linalg::naive::dense_matrix</span>::<span class="kw-2">*</span>;
    <span class="kw">use</span> <span class="ident"><span class="kw">crate</span>::metrics</span>::{<span class="ident">accuracy</span>, <span class="ident">mean_absolute_error</span>};
    <span class="kw">use</span> <span class="ident"><span class="kw">crate</span>::model_selection::kfold::KFold</span>;
    <span class="kw">use</span> <span class="ident"><span class="kw">crate</span>::neighbors::knn_regressor::KNNRegressor</span>;

    <span class="attribute">#[<span class="ident">cfg_attr</span>(<span class="ident">target_arch</span> <span class="op">=</span> <span class="string">&quot;wasm32&quot;</span>, <span class="ident">wasm_bindgen_test::wasm_bindgen_test</span>)]</span>
    <span class="attribute">#[<span class="ident">test</span>]</span>
    <span class="kw">fn</span> <span class="ident">run_train_test_split</span>() {
        <span class="kw">let</span> <span class="ident">n</span> <span class="op">=</span> <span class="number">123</span>;
        <span class="kw">let</span> <span class="ident">x</span>: <span class="ident">DenseMatrix</span><span class="op">&lt;</span><span class="ident">f64</span><span class="op">&gt;</span> <span class="op">=</span> <span class="ident">DenseMatrix::rand</span>(<span class="ident">n</span>, <span class="number">3</span>);
        <span class="kw">let</span> <span class="ident">y</span> <span class="op">=</span> <span class="macro">vec!</span>[<span class="number">0f64</span>; <span class="ident">n</span>];

        <span class="kw">let</span> (<span class="ident">x_train</span>, <span class="ident">x_test</span>, <span class="ident">y_train</span>, <span class="ident">y_test</span>) <span class="op">=</span> <span class="ident">train_test_split</span>(<span class="kw-2">&amp;</span><span class="ident">x</span>, <span class="kw-2">&amp;</span><span class="ident">y</span>, <span class="number">0.2</span>, <span class="bool-val">true</span>);

        <span class="macro">assert!</span>(
            <span class="ident">x_train</span>.<span class="ident">shape</span>().<span class="number">0</span> <span class="op">&gt;</span> (<span class="ident">n</span> <span class="kw">as</span> <span class="ident">f64</span> <span class="op">*</span> <span class="number">0.65</span>) <span class="kw">as</span> <span class="ident">usize</span>
                <span class="op">&amp;&amp;</span> <span class="ident">x_train</span>.<span class="ident">shape</span>().<span class="number">0</span> <span class="op">&lt;</span> (<span class="ident">n</span> <span class="kw">as</span> <span class="ident">f64</span> <span class="op">*</span> <span class="number">0.95</span>) <span class="kw">as</span> <span class="ident">usize</span>
        );
        <span class="macro">assert!</span>(
            <span class="ident">x_test</span>.<span class="ident">shape</span>().<span class="number">0</span> <span class="op">&gt;</span> (<span class="ident">n</span> <span class="kw">as</span> <span class="ident">f64</span> <span class="op">*</span> <span class="number">0.05</span>) <span class="kw">as</span> <span class="ident">usize</span>
                <span class="op">&amp;&amp;</span> <span class="ident">x_test</span>.<span class="ident">shape</span>().<span class="number">0</span> <span class="op">&lt;</span> (<span class="ident">n</span> <span class="kw">as</span> <span class="ident">f64</span> <span class="op">*</span> <span class="number">0.35</span>) <span class="kw">as</span> <span class="ident">usize</span>
        );
        <span class="macro">assert_eq!</span>(<span class="ident">x_train</span>.<span class="ident">shape</span>().<span class="number">0</span>, <span class="ident">y_train</span>.<span class="ident">len</span>());
        <span class="macro">assert_eq!</span>(<span class="ident">x_test</span>.<span class="ident">shape</span>().<span class="number">0</span>, <span class="ident">y_test</span>.<span class="ident">len</span>());
    }

    <span class="attribute">#[<span class="ident">derive</span>(<span class="ident">Clone</span>)]</span>
    <span class="kw">struct</span> <span class="ident">NoParameters</span> {}

    <span class="attribute">#[<span class="ident">cfg_attr</span>(<span class="ident">target_arch</span> <span class="op">=</span> <span class="string">&quot;wasm32&quot;</span>, <span class="ident">wasm_bindgen_test::wasm_bindgen_test</span>)]</span>
    <span class="attribute">#[<span class="ident">test</span>]</span>
    <span class="kw">fn</span> <span class="ident">test_cross_validate_biased</span>() {
        <span class="kw">struct</span> <span class="ident">BiasedEstimator</span> {}

        <span class="kw">impl</span> <span class="ident">BiasedEstimator</span> {
            <span class="kw">fn</span> <span class="ident">fit</span><span class="op">&lt;</span><span class="ident">M</span>: <span class="ident">Matrix</span><span class="op">&lt;</span><span class="ident">f32</span><span class="op">&gt;</span><span class="op">&gt;</span>(
                <span class="kw">_</span>: <span class="kw-2">&amp;</span><span class="ident">M</span>,
                <span class="kw">_</span>: <span class="kw-2">&amp;</span><span class="ident">M::RowVector</span>,
                <span class="kw">_</span>: <span class="ident">NoParameters</span>,
            ) -&gt; <span class="prelude-ty">Result</span><span class="op">&lt;</span><span class="ident">BiasedEstimator</span>, <span class="ident">Failed</span><span class="op">&gt;</span> {
                <span class="prelude-val">Ok</span>(<span class="ident">BiasedEstimator</span> {})
            }
        }

        <span class="kw">impl</span><span class="op">&lt;</span><span class="ident">M</span>: <span class="ident">Matrix</span><span class="op">&lt;</span><span class="ident">f32</span><span class="op">&gt;</span><span class="op">&gt;</span> <span class="ident">Predictor</span><span class="op">&lt;</span><span class="ident">M</span>, <span class="ident">M::RowVector</span><span class="op">&gt;</span> <span class="kw">for</span> <span class="ident">BiasedEstimator</span> {
            <span class="kw">fn</span> <span class="ident">predict</span>(<span class="kw-2">&amp;</span><span class="self">self</span>, <span class="ident">x</span>: <span class="kw-2">&amp;</span><span class="ident">M</span>) -&gt; <span class="prelude-ty">Result</span><span class="op">&lt;</span><span class="ident">M::RowVector</span>, <span class="ident">Failed</span><span class="op">&gt;</span> {
                <span class="kw">let</span> (<span class="ident">n</span>, <span class="kw">_</span>) <span class="op">=</span> <span class="ident">x</span>.<span class="ident">shape</span>();
                <span class="prelude-val">Ok</span>(<span class="ident">M::RowVector::zeros</span>(<span class="ident">n</span>))
            }
        }

        <span class="kw">let</span> <span class="ident">x</span> <span class="op">=</span> <span class="ident">DenseMatrix::from_2d_array</span>(<span class="kw-2">&amp;</span>[
            <span class="kw-2">&amp;</span>[<span class="number">5.1</span>, <span class="number">3.5</span>, <span class="number">1.4</span>, <span class="number">0.2</span>],
            <span class="kw-2">&amp;</span>[<span class="number">4.9</span>, <span class="number">3.0</span>, <span class="number">1.4</span>, <span class="number">0.2</span>],
            <span class="kw-2">&amp;</span>[<span class="number">4.7</span>, <span class="number">3.2</span>, <span class="number">1.3</span>, <span class="number">0.2</span>],
            <span class="kw-2">&amp;</span>[<span class="number">4.6</span>, <span class="number">3.1</span>, <span class="number">1.5</span>, <span class="number">0.2</span>],
            <span class="kw-2">&amp;</span>[<span class="number">5.0</span>, <span class="number">3.6</span>, <span class="number">1.4</span>, <span class="number">0.2</span>],
            <span class="kw-2">&amp;</span>[<span class="number">5.4</span>, <span class="number">3.9</span>, <span class="number">1.7</span>, <span class="number">0.4</span>],
            <span class="kw-2">&amp;</span>[<span class="number">4.6</span>, <span class="number">3.4</span>, <span class="number">1.4</span>, <span class="number">0.3</span>],
            <span class="kw-2">&amp;</span>[<span class="number">5.0</span>, <span class="number">3.4</span>, <span class="number">1.5</span>, <span class="number">0.2</span>],
            <span class="kw-2">&amp;</span>[<span class="number">4.4</span>, <span class="number">2.9</span>, <span class="number">1.4</span>, <span class="number">0.2</span>],
            <span class="kw-2">&amp;</span>[<span class="number">4.9</span>, <span class="number">3.1</span>, <span class="number">1.5</span>, <span class="number">0.1</span>],
            <span class="kw-2">&amp;</span>[<span class="number">7.0</span>, <span class="number">3.2</span>, <span class="number">4.7</span>, <span class="number">1.4</span>],
            <span class="kw-2">&amp;</span>[<span class="number">6.4</span>, <span class="number">3.2</span>, <span class="number">4.5</span>, <span class="number">1.5</span>],
            <span class="kw-2">&amp;</span>[<span class="number">6.9</span>, <span class="number">3.1</span>, <span class="number">4.9</span>, <span class="number">1.5</span>],
            <span class="kw-2">&amp;</span>[<span class="number">5.5</span>, <span class="number">2.3</span>, <span class="number">4.0</span>, <span class="number">1.3</span>],
            <span class="kw-2">&amp;</span>[<span class="number">6.5</span>, <span class="number">2.8</span>, <span class="number">4.6</span>, <span class="number">1.5</span>],
            <span class="kw-2">&amp;</span>[<span class="number">5.7</span>, <span class="number">2.8</span>, <span class="number">4.5</span>, <span class="number">1.3</span>],
            <span class="kw-2">&amp;</span>[<span class="number">6.3</span>, <span class="number">3.3</span>, <span class="number">4.7</span>, <span class="number">1.6</span>],
            <span class="kw-2">&amp;</span>[<span class="number">4.9</span>, <span class="number">2.4</span>, <span class="number">3.3</span>, <span class="number">1.0</span>],
            <span class="kw-2">&amp;</span>[<span class="number">6.6</span>, <span class="number">2.9</span>, <span class="number">4.6</span>, <span class="number">1.3</span>],
            <span class="kw-2">&amp;</span>[<span class="number">5.2</span>, <span class="number">2.7</span>, <span class="number">3.9</span>, <span class="number">1.4</span>],
        ]);
        <span class="kw">let</span> <span class="ident">y</span> <span class="op">=</span> <span class="macro">vec!</span>[
            <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>,
        ];

        <span class="kw">let</span> <span class="ident">cv</span> <span class="op">=</span> <span class="ident">KFold</span> {
            <span class="ident">n_splits</span>: <span class="number">5</span>,
            ..<span class="ident">KFold::default</span>()
        };

        <span class="kw">let</span> <span class="ident">results</span> <span class="op">=</span>
            <span class="ident">cross_validate</span>(<span class="ident">BiasedEstimator::fit</span>, <span class="kw-2">&amp;</span><span class="ident">x</span>, <span class="kw-2">&amp;</span><span class="ident">y</span>, <span class="ident">NoParameters</span> {}, <span class="ident">cv</span>, <span class="kw-2">&amp;</span><span class="ident">accuracy</span>).<span class="ident">unwrap</span>();

        <span class="macro">assert_eq!</span>(<span class="number">0.4</span>, <span class="ident">results</span>.<span class="ident">mean_test_score</span>());
        <span class="macro">assert_eq!</span>(<span class="number">0.4</span>, <span class="ident">results</span>.<span class="ident">mean_train_score</span>());
    }

    <span class="attribute">#[<span class="ident">cfg_attr</span>(<span class="ident">target_arch</span> <span class="op">=</span> <span class="string">&quot;wasm32&quot;</span>, <span class="ident">wasm_bindgen_test::wasm_bindgen_test</span>)]</span>
    <span class="attribute">#[<span class="ident">test</span>]</span>
    <span class="kw">fn</span> <span class="ident">test_cross_validate_knn</span>() {
        <span class="kw">let</span> <span class="ident">x</span> <span class="op">=</span> <span class="ident">DenseMatrix::from_2d_array</span>(<span class="kw-2">&amp;</span>[
            <span class="kw-2">&amp;</span>[<span class="number">234.289</span>, <span class="number">235.6</span>, <span class="number">159.</span>, <span class="number">107.608</span>, <span class="number">1947.</span>, <span class="number">60.323</span>],
            <span class="kw-2">&amp;</span>[<span class="number">259.426</span>, <span class="number">232.5</span>, <span class="number">145.6</span>, <span class="number">108.632</span>, <span class="number">1948.</span>, <span class="number">61.122</span>],
            <span class="kw-2">&amp;</span>[<span class="number">258.054</span>, <span class="number">368.2</span>, <span class="number">161.6</span>, <span class="number">109.773</span>, <span class="number">1949.</span>, <span class="number">60.171</span>],
            <span class="kw-2">&amp;</span>[<span class="number">284.599</span>, <span class="number">335.1</span>, <span class="number">165.</span>, <span class="number">110.929</span>, <span class="number">1950.</span>, <span class="number">61.187</span>],
            <span class="kw-2">&amp;</span>[<span class="number">328.975</span>, <span class="number">209.9</span>, <span class="number">309.9</span>, <span class="number">112.075</span>, <span class="number">1951.</span>, <span class="number">63.221</span>],
            <span class="kw-2">&amp;</span>[<span class="number">346.999</span>, <span class="number">193.2</span>, <span class="number">359.4</span>, <span class="number">113.27</span>, <span class="number">1952.</span>, <span class="number">63.639</span>],
            <span class="kw-2">&amp;</span>[<span class="number">365.385</span>, <span class="number">187.</span>, <span class="number">354.7</span>, <span class="number">115.094</span>, <span class="number">1953.</span>, <span class="number">64.989</span>],
            <span class="kw-2">&amp;</span>[<span class="number">363.112</span>, <span class="number">357.8</span>, <span class="number">335.</span>, <span class="number">116.219</span>, <span class="number">1954.</span>, <span class="number">63.761</span>],
            <span class="kw-2">&amp;</span>[<span class="number">397.469</span>, <span class="number">290.4</span>, <span class="number">304.8</span>, <span class="number">117.388</span>, <span class="number">1955.</span>, <span class="number">66.019</span>],
            <span class="kw-2">&amp;</span>[<span class="number">419.18</span>, <span class="number">282.2</span>, <span class="number">285.7</span>, <span class="number">118.734</span>, <span class="number">1956.</span>, <span class="number">67.857</span>],
            <span class="kw-2">&amp;</span>[<span class="number">442.769</span>, <span class="number">293.6</span>, <span class="number">279.8</span>, <span class="number">120.445</span>, <span class="number">1957.</span>, <span class="number">68.169</span>],
            <span class="kw-2">&amp;</span>[<span class="number">444.546</span>, <span class="number">468.1</span>, <span class="number">263.7</span>, <span class="number">121.95</span>, <span class="number">1958.</span>, <span class="number">66.513</span>],
            <span class="kw-2">&amp;</span>[<span class="number">482.704</span>, <span class="number">381.3</span>, <span class="number">255.2</span>, <span class="number">123.366</span>, <span class="number">1959.</span>, <span class="number">68.655</span>],
            <span class="kw-2">&amp;</span>[<span class="number">502.601</span>, <span class="number">393.1</span>, <span class="number">251.4</span>, <span class="number">125.368</span>, <span class="number">1960.</span>, <span class="number">69.564</span>],
            <span class="kw-2">&amp;</span>[<span class="number">518.173</span>, <span class="number">480.6</span>, <span class="number">257.2</span>, <span class="number">127.852</span>, <span class="number">1961.</span>, <span class="number">69.331</span>],
            <span class="kw-2">&amp;</span>[<span class="number">554.894</span>, <span class="number">400.7</span>, <span class="number">282.7</span>, <span class="number">130.081</span>, <span class="number">1962.</span>, <span class="number">70.551</span>],
        ]);
        <span class="kw">let</span> <span class="ident">y</span> <span class="op">=</span> <span class="macro">vec!</span>[
            <span class="number">83.0</span>, <span class="number">88.5</span>, <span class="number">88.2</span>, <span class="number">89.5</span>, <span class="number">96.2</span>, <span class="number">98.1</span>, <span class="number">99.0</span>, <span class="number">100.0</span>, <span class="number">101.2</span>, <span class="number">104.6</span>, <span class="number">108.4</span>, <span class="number">110.8</span>, <span class="number">112.6</span>,
            <span class="number">114.2</span>, <span class="number">115.7</span>, <span class="number">116.9</span>,
        ];

        <span class="kw">let</span> <span class="ident">cv</span> <span class="op">=</span> <span class="ident">KFold</span> {
            <span class="ident">n_splits</span>: <span class="number">5</span>,
            ..<span class="ident">KFold::default</span>()
        };

        <span class="kw">let</span> <span class="ident">results</span> <span class="op">=</span> <span class="ident">cross_validate</span>(
            <span class="ident">KNNRegressor::fit</span>,
            <span class="kw-2">&amp;</span><span class="ident">x</span>,
            <span class="kw-2">&amp;</span><span class="ident">y</span>,
            <span class="ident">Default::default</span>(),
            <span class="ident">cv</span>,
            <span class="kw-2">&amp;</span><span class="ident">mean_absolute_error</span>,
        )
        .<span class="ident">unwrap</span>();

        <span class="macro">assert!</span>(<span class="ident">results</span>.<span class="ident">mean_test_score</span>() <span class="op">&lt;</span> <span class="number">15.0</span>);
        <span class="macro">assert!</span>(<span class="ident">results</span>.<span class="ident">mean_train_score</span>() <span class="op">&lt;</span> <span class="ident">results</span>.<span class="ident">mean_test_score</span>());
    }

    <span class="attribute">#[<span class="ident">cfg_attr</span>(<span class="ident">target_arch</span> <span class="op">=</span> <span class="string">&quot;wasm32&quot;</span>, <span class="ident">wasm_bindgen_test::wasm_bindgen_test</span>)]</span>
    <span class="attribute">#[<span class="ident">test</span>]</span>
    <span class="kw">fn</span> <span class="ident">test_cross_val_predict_knn</span>() {
        <span class="kw">let</span> <span class="ident">x</span> <span class="op">=</span> <span class="ident">DenseMatrix::from_2d_array</span>(<span class="kw-2">&amp;</span>[
            <span class="kw-2">&amp;</span>[<span class="number">234.289</span>, <span class="number">235.6</span>, <span class="number">159.</span>, <span class="number">107.608</span>, <span class="number">1947.</span>, <span class="number">60.323</span>],
            <span class="kw-2">&amp;</span>[<span class="number">259.426</span>, <span class="number">232.5</span>, <span class="number">145.6</span>, <span class="number">108.632</span>, <span class="number">1948.</span>, <span class="number">61.122</span>],
            <span class="kw-2">&amp;</span>[<span class="number">258.054</span>, <span class="number">368.2</span>, <span class="number">161.6</span>, <span class="number">109.773</span>, <span class="number">1949.</span>, <span class="number">60.171</span>],
            <span class="kw-2">&amp;</span>[<span class="number">284.599</span>, <span class="number">335.1</span>, <span class="number">165.</span>, <span class="number">110.929</span>, <span class="number">1950.</span>, <span class="number">61.187</span>],
            <span class="kw-2">&amp;</span>[<span class="number">328.975</span>, <span class="number">209.9</span>, <span class="number">309.9</span>, <span class="number">112.075</span>, <span class="number">1951.</span>, <span class="number">63.221</span>],
            <span class="kw-2">&amp;</span>[<span class="number">346.999</span>, <span class="number">193.2</span>, <span class="number">359.4</span>, <span class="number">113.27</span>, <span class="number">1952.</span>, <span class="number">63.639</span>],
            <span class="kw-2">&amp;</span>[<span class="number">365.385</span>, <span class="number">187.</span>, <span class="number">354.7</span>, <span class="number">115.094</span>, <span class="number">1953.</span>, <span class="number">64.989</span>],
            <span class="kw-2">&amp;</span>[<span class="number">363.112</span>, <span class="number">357.8</span>, <span class="number">335.</span>, <span class="number">116.219</span>, <span class="number">1954.</span>, <span class="number">63.761</span>],
            <span class="kw-2">&amp;</span>[<span class="number">397.469</span>, <span class="number">290.4</span>, <span class="number">304.8</span>, <span class="number">117.388</span>, <span class="number">1955.</span>, <span class="number">66.019</span>],
            <span class="kw-2">&amp;</span>[<span class="number">419.18</span>, <span class="number">282.2</span>, <span class="number">285.7</span>, <span class="number">118.734</span>, <span class="number">1956.</span>, <span class="number">67.857</span>],
            <span class="kw-2">&amp;</span>[<span class="number">442.769</span>, <span class="number">293.6</span>, <span class="number">279.8</span>, <span class="number">120.445</span>, <span class="number">1957.</span>, <span class="number">68.169</span>],
            <span class="kw-2">&amp;</span>[<span class="number">444.546</span>, <span class="number">468.1</span>, <span class="number">263.7</span>, <span class="number">121.95</span>, <span class="number">1958.</span>, <span class="number">66.513</span>],
            <span class="kw-2">&amp;</span>[<span class="number">482.704</span>, <span class="number">381.3</span>, <span class="number">255.2</span>, <span class="number">123.366</span>, <span class="number">1959.</span>, <span class="number">68.655</span>],
            <span class="kw-2">&amp;</span>[<span class="number">502.601</span>, <span class="number">393.1</span>, <span class="number">251.4</span>, <span class="number">125.368</span>, <span class="number">1960.</span>, <span class="number">69.564</span>],
            <span class="kw-2">&amp;</span>[<span class="number">518.173</span>, <span class="number">480.6</span>, <span class="number">257.2</span>, <span class="number">127.852</span>, <span class="number">1961.</span>, <span class="number">69.331</span>],
            <span class="kw-2">&amp;</span>[<span class="number">554.894</span>, <span class="number">400.7</span>, <span class="number">282.7</span>, <span class="number">130.081</span>, <span class="number">1962.</span>, <span class="number">70.551</span>],
        ]);
        <span class="kw">let</span> <span class="ident">y</span> <span class="op">=</span> <span class="macro">vec!</span>[
            <span class="number">83.0</span>, <span class="number">88.5</span>, <span class="number">88.2</span>, <span class="number">89.5</span>, <span class="number">96.2</span>, <span class="number">98.1</span>, <span class="number">99.0</span>, <span class="number">100.0</span>, <span class="number">101.2</span>, <span class="number">104.6</span>, <span class="number">108.4</span>, <span class="number">110.8</span>, <span class="number">112.6</span>,
            <span class="number">114.2</span>, <span class="number">115.7</span>, <span class="number">116.9</span>,
        ];

        <span class="kw">let</span> <span class="ident">cv</span> <span class="op">=</span> <span class="ident">KFold</span> {
            <span class="ident">n_splits</span>: <span class="number">2</span>,
            ..<span class="ident">KFold::default</span>()
        };

        <span class="kw">let</span> <span class="ident">y_hat</span> <span class="op">=</span> <span class="ident">cross_val_predict</span>(<span class="ident">KNNRegressor::fit</span>, <span class="kw-2">&amp;</span><span class="ident">x</span>, <span class="kw-2">&amp;</span><span class="ident">y</span>, <span class="ident">Default::default</span>(), <span class="ident">cv</span>).<span class="ident">unwrap</span>();

        <span class="macro">assert!</span>(<span class="ident">mean_absolute_error</span>(<span class="kw-2">&amp;</span><span class="ident">y</span>, <span class="kw-2">&amp;</span><span class="ident">y_hat</span>) <span class="op">&lt;</span> <span class="number">10.0</span>);
    }
}
</code></pre></div>
</section></div></main><div id="rustdoc-vars" data-root-path="../../../" data-current-crate="smartcore" data-themes="ayu,dark,light" data-resource-suffix="" data-rustdoc-version="1.63.0-nightly (10f4ce324 2022-06-22)" ></div>
</body></html>